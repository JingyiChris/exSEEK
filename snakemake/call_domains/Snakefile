shell.prefix('set -x;')
configfile: 'snakemake/config.json'

if not config.get('sample_id_file'):
    raise ValueError('config.sample_id_file is empty')

with open(config['sample_id_file'], 'r') as f:
    sample_ids = f.read().split()

output_dir = config['output_dir']
rna_types = config['rna_types']
piranha_path = '../piranha-exrna-1.2.1/bin'
normalize_methods = config['normalize_methods']

def get_all_inputs(wildcards):
    available_inputs = dict(
        piranha_peak_cov_matrix=expand('{output_dir}/count_matrix/domains_{pvalue}.txt',
            output_dir=output_dir, pvalue=config['pvalues']),
        merge_annotation_bed=expand('{annotation_dir}/bed/genome.bed',
            annotation_dir=config['annotation_dir']),
        normalize_matrix=expand('{output_dir}/normalized_matrix/{normalize_method}/domains_{pvalue}.txt',
            output_dir=output_dir, pvalue=config['pvalues'], normalize_method=normalize_methods)
    )
    enabled_inputs = list(available_inputs)
    inputs = []
    for key, l in available_inputs.items():
        if key in enabled_inputs:
            inputs += l
    return inputs

rule all:
    input:
        get_all_inputs

rule gtf_to_bed:
    input:
        '{annotation_dir}/gtf/{database}.gtf'
    output:
        '{annotation_dir}/bed/{database}.bed'
    shell:
        '''gffread --bed -o- {input} \
            | bedtools sort > {output}
        '''

rule merge_annotation_bed:
    input:
        lambda wildcards: expand('{annotation_dir}/bed/{database}.bed', 
            annotation_dir=wildcards.annotation_dir,
            database=config['annotation_databases'])
    output:
        '{annotation_dir}/bed/genome.bed'
    shell:
        '''cat {input} | bedtools sort > {output}
        '''

rule bam_to_bed:
    input:
        '{output_dir}/gbam/{sample_id}/{rna_type}.bam'
    output:
        '{output_dir}/gbed_by_rnatype/{sample_id}/{rna_type}.bed.gz'
    threads: config['threads']
    shell:
        '''bedtools bamtobed -i {input} | pigz -c -p {threads} > {output}
        '''

rule merge_bam_by_rnatype:
    input:
        lambda wildcards: expand('{output_dir}/gbed_by_rnatype/{sample_id}/{rna_type}.bed.gz',
            output_dir=wildcards.output_dir, sample_id=wildcards.sample_id, rna_type=rna_types)
    output:
        '{output_dir}/gbed/{sample_id}.bed.gz'
    threads: 2
    shell:
        '''pigz -p {threads} -d -c {input} \
            | bedtools sort \
            | pigz -c -p {threads} > {output}'''

rule bin_counts:
    input:
        bed='{output_dir}/gbed/{sample_id}.bed.gz',
        chrom_sizes='{annotation_dir}/chrom_sizes/genome'.format(
            annotation_dir=config['annotation_dir'])
    output:
        '{output_dir}/gbincov/{bin_size}/{sample_id}.{strand}.bed'
    shell:
        '''pigz -d -c {input.bed} \
            | awk -F'\t' -v s={wildcards.strand} '$6 == s' \
            | {piranha_path}/BinCoverage -c {input.chrom_sizes} -i /dev/stdin -o {output}
        '''

rule call_domains:
    input:
        '{output_dir}/gbincov/{bin_size}/{sample_id}.{strand}.bed'
    output:
        '{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.{strand}.bed'
    params:
        distribution=config['distribution']
    shell:
        '''{piranha_path}/Piranha -s -b {wildcards.bin_size} -d {params.distribution} \
            -p 0.{wildcards.pvalue} -T bin_cov \
            {input} > {output}
        '''

rule call_domains_two_round:
    input:
        '{output_dir}/gbincov/{bin_size}/{sample_id}.{strand}.bed'
    output:
        round1='{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.{strand}.round1.bed',
        round2='{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.{strand}.round2.bed',
        merged='{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.{strand}.bed'
    shell:
        '''{piranha_path}/Piranha -s -b {wildcards.bin_size} -d {wildcards.method} -p 0.{wildcards.pvalue} \
            -T bin_cov {input} -o {output.round1}
        bedtools intersect -v -a {input} -b {output.round1} \
            | {piranha_path}/Piranha -s -b {wildcards.bin_size} \
            -d {wildcards.method} -p 0.{wildcards.pvalue} -T bin_cov /dev/stdin -o {output.round2}
        cat {output.round1} {output.round2} \
            | bedtools sort \
            | bedtools merge -c 4,5,6,7 -o distinct,mean,distinct,mean \
            | awk 'BEGIN{{OFS="\t";FS="\t"}}{{print $1,$2,$3,"peak_"NR,$5,$6}}' > {output.merged}
        '''

rule merge_domains_by_strand:
    input:
        pos='{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.+.bed',
        neg='{output_dir}/gdomains_by_strand/{bin_size}/{pvalue}/{sample_id}.-.bed'
    output:
        '{output_dir}/gdomains_sample/{bin_size}/{pvalue}/{sample_id}.bed'
    shell:
        '''{{
            awk 'BEGIN{{OFS="\t";FS="\t"}}{{print $1,$2,$3,$4,$5,"+"}}' {input.pos}
            awk 'BEGIN{{OFS="\t";FS="\t"}}{{print $1,$2,$3,$4,$5,"-"}}' {input.neg}
        }} | bedtools sort > {output}
        '''

rule domain_recurrence:
    input:
        bed=lambda wildcards: expand('{output_dir}/gdomains_sample/{bin_size}/{pvalue}/{sample_id}.bed',
            output_dir=wildcards.output_dir,
            bin_size=wildcards.bin_size,
            pvalue=wildcards.pvalue,
            sample_id=sample_ids),
        chrom_sizes='{annotation_dir}/chrom_sizes/genome'.format(
            annotation_dir=config['annotation_dir'])
    output:
        '{output_dir}/gdomains_recurrence_by_strand/{bin_size}/{pvalue}.{strand}.bed'
    shell:
        '''cat {input.bed} \
            | bedtools sort \
            | bedtools genomecov -i - -strand {wildcards.strand} -g {input.chrom_sizes} -bg \
            | awk -v s={wildcards.strand} 'BEGIN{{OFS="\t";FS="\t"}}{{print $1,$2,$3,"X",$4,s}}' \
            > {output}
        '''

rule merge_domain_recurrence_by_strand:
    input:
        pos='{output_dir}/gdomains_recurrence_by_strand/{bin_size}/{pvalue}.+.bed',
        neg='{output_dir}/gdomains_recurrence_by_strand/{bin_size}/{pvalue}.-.bed'
    output:
        '{output_dir}/gdomains_recurrence/{bin_size}/{pvalue}.bed'
    shell:
        '''cat {input.pos} {input.neg} \
            | bedtools sort > {output}
        '''

rule filter_domain_by_recurrence:
    input:
        '{output_dir}/gdomains_recurrence/{bin_size}/{pvalue}.bed'
    output:
        '{output_dir}/gdomains/{bin_size}/{pvalue}.bed'
    params:
        cov_threshold=len(sample_ids)*config['cov_threshold']
    shell:
        '''awk -v c={params.cov_threshold} '$5 > c' {input} \
            | bedtools merge -s -c 2,3,5,6 -o collapse,collapse,collapse,collapse \
            | awk 'BEGIN{{OFS="\t";FS="\t"}} 
            {{split($4,a,/,/); split($5,b,/,/); split($6,c,/,/); split($7,d,/,/);
            cov=0.0;for(i=1;i<=length(a);i++){{cov+=c[i]*(b[i]-a[i]);}} 
            cov /= $3-$2;
            print $1,$2,$3,"peak_" NR,cov,d[1]
            }}' > {output}
        '''

rule domain_read_counts:
    input:
        bed='{output_dir}/gbed/{sample_id}.bed.gz',
        domains='{output_dir}/gdomains/{bin_size}/{pvalue}.bed'
    output:
        '{output_dir}/gdomain_counts/{bin_size}/{pvalue}/{sample_id}.bed'
    threads: config['threads']
    shell:
        '''pigz -d -c -p {threads} {input.bed} \
            | bedtools coverage -s -sorted -counts \
                -a {input.domains} -b - \
            | awk 'BEGIN{{OFS="\t";FS="\t"}}{{print $1,$2,$3,$4,$7,$6}}' \
                > {output}
        '''

rule annotate_domains:
    input:
        domains='{output_dir}/gdomains/{bin_size}/{pvalue}.bed',
        annotations='{annotation_dir}/bed/genome.bed'
    output:
        '{output_dir}/gdomains_annotated/{bin_size}/{pvalue}.gene_ids.bed'
    shell:
        '''bedtools map -s -counts -a {input.domains} -b {input.annotation} \
            -c 4 -o collapse > {output}
        '''

rule summarize_domains:
    input:
        '{output_dir}/gdomain_counts/{bin_size}/{pvalue}.bed'
    output:
        directory('{output_dir}/summary/call_domains')
    shell:
        '''bin/report.py summarize_domains -i {input}
        '''

rule domain_count_matrix:
    input:
        peaks=lambda wildcards: expand('{output_dir}/gdomain_counts/{bin_size}/{pvalue}/{sample_id}.bed',
            output_dir=wildcards.output_dir,
            bin_size=config['bin_size'], 
            pvalue=wildcards.pvalue, 
            sample_id=sample_ids),
    output:
        '{output_dir}/count_matrix/domains_{pvalue}.txt'
    params:

    run:
        import pandas as pd
        import re

        pat_cov = re.compile(r'{output_dir}/gdomain_counts/(?P<bin_size>[^/]+)/(?P<pvalue>[^/]+)/(?P<sample_id>[^\.]+).bed'.format(output_dir=output_dir))
        mat = []
        peak_labels = None
        for filename in input.peaks:
            sample_id = pat_cov.match(filename).groupdict()['sample_id']
            df = pd.read_table(filename, header=None)
            if peak_labels is None:
                peak_labels = df.iloc[:, 3].values
            df.index = df.iloc[:, 3]
            cov = df.iloc[:, 4].copy()
            cov.name = sample_id
            mat.append(cov)
        mat = pd.concat(mat, axis=1)
        mat.index = peak_labels
        mat.index.name = 'peak'
        mat.to_csv(output[0], sep='\t', header=True, index=True)

rule normalize_matrix:
    input:
        '{output_dir}/count_matrix/domains_{pvalue}.txt'
    output:
        '{output_dir}/normalized_matrix/{normalize_method}/domains_{pvalue}.txt'
    shell:
        '''bin/normalize.py -i {input} -m {wildcards.normalize_method} -o {output}
        '''