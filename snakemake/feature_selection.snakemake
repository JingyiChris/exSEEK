shell.prefix('set -x; set -e;')

scalers = ['robust']
#classifiers = ['random_forest', 'logistic_regression']
classifiers = ['random_forest']
#classifiers = ['linear_svm']
#classifiers += [s + '_rfe' for s in classifiers]
#n_selects = [30, 50, 100]
#n_selects = [10, 20, 30, 40, 50]
#n_selects = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50]
n_selects = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
compute_sample_weights = [1]
#resample_methods = ['jackknife', 'bootstrap']
resample_methods = ['bootstrap']

groups = {}
for group in datasets.keys():
    for dataset in datasets[group]:
        groups[dataset] = group

resample_methods = config['resample_methods']
splitters = config['splitters']
compare_classes = config['compare_classes']
n_selects = config['n_selects']
classifiers = config['classifiers']
scalers = config['scalers']

from functools import reduce

def get_all_inputs(wildcards):
    available_inputs['evaluate'] = []
    for group in datasets.keys():
        for dataset in datasets[group]:
            available_inputs['evaluate'] += expand('output/{dataset}/feature_selection/{preprocess_method}/{compare_classes}/{classifier}.{n_select}.{select_method}.{splitter}',
                dataset=dataset, classifier=classifiers, select_method=select_methods, 
                compare_classes=compare_classes[group], n_select=n_selects,
                splitter=splitters)
    enabled_inputs = [
        'evaluate'
    ]
    inputs = []
    for key, l in available_inputs.items():
        if key in enabled_inputs:
            inputs += l
    return inputs

rule all:
    input:
        get_all_inputs


rule evaluate:
    input:
        matrix='output/cpm_matrix/{dataset}.txt',
        sample_classes=lambda wildcards: 'metadata/sample_classes.{group}.txt'.format(group=groups[wildcards.dataset])
    output:
        directory('output/feature_selection/{dataset}/{compare_classes}/{classifier}.{n_select}.{select_method}.{splitter}')
    params:
        rfe=lambda wildcards: {True: '--rfe --rfe-resample-method jackknife --rfe-max-runs 50'},
        select_method=lambda wildcards: {'rfe': '--rfe --rfe-step 0.1',
            'ranking': '',
            'robust': '--robust-select --robust-max-runs 50 --robust-resample-method jackknife --robust-jackknife-remove 0.1' }[wildcards.select_method],
        positive_class=lambda wildcards: compare_classes[groups[wildcards.dataset]][wildcards.compare_classes][1],
        negative_class=lambda wildcards: compare_classes[groups[wildcards.dataset]][wildcards.compare_classes][0],
        n_splits=lambda wildcards: {'shuffle_split': 50, 'stratified_shuffle_split': 50}.get(wildcards.splitter, 5),
        use_log=lambda wildcards: '' if (groups[wildcards.dataset] in 'qpcr') or (wildcards.dataset.startswith('nolabel.logged.ruvs')) else '--use-log',
        remove_zero_features=lambda wildcards: '' if groups[wildcards.dataset] in 'qpcr' else '--remove-zero-features 0.2'
    shell:
        '''bin/feature_selection.py evaluate -i {input.matrix} \
            --transpose {params.use_log} --sample-classes {input.sample_classes} \
            --positive-class '{params.positive_class}' --negative-class '{params.negative_class}' \
            --scaler robust --method {wildcards.classifier} --n-select {wildcards.n_select} \
            --splitter {wildcards.splitter} \
            {params.select_method} \
            --n-splits {params.n_splits} \
            --compute-sample-weight \
            {params.remove_zero_features} \
            -o {output}
        '''
