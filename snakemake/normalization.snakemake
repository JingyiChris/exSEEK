shell.prefix('set -x;')
include: 'common.snakemake'


def get_all_inputs(wildcards):
    available_inputs = []
    for batch_removal_method in config['batch_removal_methods']:
        if batch_removal_method == 'Combat':
            template = '{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.Batch_{batch_removal_method}_{batch_index}.{count_method}.txt'
            available_inputs += expand(template,
                output_dir=output_dir,
                imputation_method=config['imputation_methods'],
                normalization_method=config['normalization_methods'],
                batch_removal_method=batch_removal_method,
                batch_index=config['batch_indices'],
                count_method=config['count_method'])
        else:
            template = '{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.Batch_{batch_removal_method}.{count_method}.txt'
            available_inputs += expand(template,
                output_dir=output_dir,
                imputation_method=config['imputation_methods'],
                normalization_method=config['normalization_methods'],
                batch_removal_method=batch_removal_method,
                count_method=config['count_method'])
    available_inputs += expand('{output_dir}/select_preprocess_method/{score}/{count_method}/selected_methods.txt',
        output_dir=output_dir, score='uca_score', count_method=config['count_method'])
    return available_inputs

rule all:
    input:
        get_all_inputs

rule filter_step:
    input:
        matrix='{output_dir}/count_matrix/{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt',
        batch_info=data_dir + '/batch_info.txt'
    output:
        '{output_dir}/matrix_processing/filter.{count_method}.txt'
    threads:
        config['threads']
    wildcard_constraints:
        count_method='(featurecounts)|(htseq)|(domains_combined)'
    params:
        filtercount=config['filtercount'],
        filtersample=config['filtersample'],
        cvthreshold=0.5,
        removetype='miRNA,piRNA',
        normtopk=20,
        imputecluster=5
    shell:
        '''Rscript {bin_dir}/matrix-process.R -s filter \
        -i {input.matrix} \
        -c {input.sample_classes} \
        -b {input.batch_info} \
        --filterout '{wildcards.output_dir}/matrix_processing/' \
        --imputeout '{wildcards.output_dir}/matrix_processing/' \
        --normalizeout '{wildcards.output_dir}/matrix_processing/' \
        --batchremoveout '{wildcards.output_dir}/matrix_processing/' \
        --imputemethod null \
        --filtercount {params.filtercount} \
        --filtersample {params.filtersample} \
        --imputecluster {params.imputecluster} \
        -p {threads} \
        --normmethod null \
        --normtopk {params.normtopk} \
        --removetype {params.removetype} \
        --cvthreshold {params.cvthreshold} \
        --batchmethod null \
        --batchindex 1
        '''

rule imputation_step:
    input:
        filter_matrix='{output_dir}/matrix_processing/filter.{count_method}.txt',
        matrix='{output_dir}/count_matrix/{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt',
        batch_info=data_dir + '/batch_info.txt'
    output:
        '{output_dir}/matrix_processing/filter.{imputation_method}.{count_method}.txt'
    threads:
        config['threads']
    params:
        filtercount=5,
        filtersample=10,
        cvthreshold=0.5,
        removetype='miRNA,piRNA',
        normtopk=20,
        imputecluster=5
    wildcard_constraints:
        imputation_method='(scimpute_count)|(viper_count)|(null)',
        count_method='(featurecounts)|(htseq)|(domains_combined)'
    shell:
        '''Rscript {bin_dir}/matrix-process.R -s imputation \
        -i {input.matrix} \
        -c {input.sample_classes} \
        -b {input.batch_info} \
        --filterout '{wildcards.output_dir}/matrix_processing/' \
        --imputeout '{wildcards.output_dir}/matrix_processing/' \
        --normalizeout '{wildcards.output_dir}/matrix_processing/' \
        --batchremoveout '{wildcards.output_dir}/matrix_processing/' \
        --imputemethod {wildcards.imputation_method} \
        --filtercount {params.filtercount} \
        --filtersample {params.filtersample} \
        --imputecluster {params.imputecluster} \
        -p {threads} \
        --normmethod null \
        --normtopk {params.normtopk} \
        --removetype {params.removetype} \
        --cvthreshold {params.cvthreshold} \
        --batchmethod null \
        --batchindex 1
        '''

rule normalization_step:
    input:
        imputation_matrix='{output_dir}/matrix_processing/filter.{imputation_method}.{count_method}.txt',
        matrix='{output_dir}/count_matrix/{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt',
        batch_info=data_dir + '/batch_info.txt'
    output:
        '{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.{count_method}.txt'
    threads:
        config['threads']
    wildcard_constraints:
        normalization_method='(SCnorm)|(TMM)|(RLE)|(CPM)|(CPM_top)|(CPM_rm)|(CPM_refer)|(null)',
        count_method='(featurecounts)|(htseq)|(domains_combined)'
    params:
        filtercount=5,
        filtersample=10,
        cvthreshold=0.5,
        removetype='miRNA,piRNA',
        normtopk=20,
        imputecluster=5
    shell:
        '''Rscript {bin_dir}/matrix-process.R -s normalization \
        -i {input.matrix} \
        -c {input.sample_classes} \
        -b {input.batch_info} \
        --filterout '{wildcards.output_dir}/matrix_processing/' \
        --imputeout '{wildcards.output_dir}/matrix_processing/' \
        --normalizeout '{wildcards.output_dir}/matrix_processing/' \
        --batchremoveout '{wildcards.output_dir}/matrix_processing/' \
        --imputemethod {wildcards.imputation_method} \
        --filtercount {params.filtercount} \
        --filtersample {params.filtersample} \
        --imputecluster {params.imputecluster} \
        -p {threads} \
        --normmethod {wildcards.normalization_method} \
        --normtopk {params.normtopk} \
        --removetype {params.removetype} \
        --cvthreshold {params.cvthreshold} \
        --batchmethod null \
        --batchindex 1
        '''

rule batch_removal_step_Combat:
    input:
        normalization_matrix='{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.{count_method}.txt',
        matrix='{output_dir}/count_matrix/{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt',
        batch_info=data_dir + '/batch_info.txt',
        reference_genes=data_dir + '/reference_genes.txt'
    output:
        '{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.Batch_{batch_removal_method}_{batch_index}.{count_method}.txt'
    threads:
        config['threads']
    params:
        filtercount=5,
        filtersample=10,
        cvthreshold=0.5,
        removetype='miRNA,piRNA',
        normtopk=20,
        imputecluster=5
    wildcard_constraints:
        batch_removal_method='Combat'
    shell:
        '''Rscript {bin_dir}/matrix-process.R -s batch_removal \
        -i {input.matrix} \
        -c {input.sample_classes} \
        -b {input.batch_info} \
        --refergenefile {input.reference_genes} \
        --filterout '{wildcards.output_dir}/matrix_processing/' \
        --imputeout '{wildcards.output_dir}/matrix_processing/' \
        --normalizeout '{wildcards.output_dir}/matrix_processing/' \
        --batchremoveout '{wildcards.output_dir}/matrix_processing/' \
        --imputemethod {wildcards.imputation_method} \
        --filtercount {params.filtercount} \
        --filtersample {params.filtersample} \
        --imputecluster {params.imputecluster} \
        -p {threads} \
        --normmethod {wildcards.normalization_method} \
        --normtopk {params.normtopk} \
        --removetype {params.removetype} \
        --cvthreshold {params.cvthreshold} \
        --batchmethod {wildcards.batch_removal_method} \
        --batchindex {wildcards.batch_index}
        '''

rule batch_removal_step_RUV:
    input:
        normalization_matrix='{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.{count_method}.txt',
        matrix='{output_dir}/count_matrix/{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt',
        batch_info=data_dir + '/batch_info.txt'
    output:
        '{output_dir}/matrix_processing/filter.{imputation_method}.Norm_{normalization_method}.Batch_{batch_removal_method}.{count_method}.txt'
    threads:
        config['threads']
    params:
        filtercount=5,
        filtersample=10,
        cvthreshold=0.5,
        removetype='miRNA,piRNA',
        normtopk=20,
        imputecluster=5
    wildcard_constraints:
        batch_removal_method='(RUV)|(null)'
    shell:
        '''Rscript {bin_dir}/matrix-process.R -s batch_removal \
        -i {input.matrix} \
        -c {input.sample_classes} \
        -b {input.batch_info} \
        --filterout '{wildcards.output_dir}/matrix_processing/' \
        --imputeout '{wildcards.output_dir}/matrix_processing/' \
        --normalizeout '{wildcards.output_dir}/matrix_processing/' \
        --batchremoveout '{wildcards.output_dir}/matrix_processing/' \
        --imputemethod {wildcards.imputation_method} \
        --filtercount {params.filtercount} \
        --filtersample {params.filtersample} \
        --imputecluster {params.imputecluster} \
        -p {threads} \
        --normmethod {wildcards.normalization_method} \
        --normtopk {params.normtopk} \
        --removetype {params.removetype} \
        --cvthreshold {params.cvthreshold} \
        --batchmethod {wildcards.batch_removal_method}
        '''

rule clustering_score:
    input:
        matrix='{output_dir}/matrix_processing/{preprocess_method}.{count_method}.txt',
        sample_classes=data_dir + '/sample_classes.txt'
    output:
        '{output_dir}/clustering_scores/{score}/{count_method}/{preprocess_method}'
    shell:
        '''{bin_dir}/feature_selection.py calculate_clustering_score \
        --matrix {input.matrix} \
        --sample-classes {input.sample_classes} --transpose --use-log > {output}
    '''

rule select_preprocess_method:
    input:
        lambda wildcards: expand('{output_dir}/clustering_scores/{score}/{count_method}/{preprocess_method}',
            output_dir=wildcards.output_dir, score=wildcards.score, 
            preprocess_method=get_preprocess_methods(), count_method=wildcards.count_method)
    output:
        summary='{output_dir}/select_preprocess_method/{score}/{count_method}/summary.txt',
        selected_methods='{output_dir}/select_preprocess_method/{score}/{count_method}/selected_methods.txt'
    params:
        n_selected_preprocess_method=3
    run:
        import pandas as pd

        scores = {}
        for score_file in input:
            preprocess_method = score_file.split('/')[-1]
            with open(score_file, 'r') as f:
                score = float(f.read())
                scores[preprocess_method] = score
        scores = pd.Series(scores)
        scores.index.name = 'preprocess_method'
        scores.name = wildcards.score
        scores = scores.sort_values(ascending=False)
        scores.to_csv(output.summary, sep='\t', na_rep='NA', index=True, header=True)

        selected_methods = scores.index.to_series()[:params.n_selected_preprocess_method]
        selected_methods.to_csv(output.selected_methods, index=False, header=False)